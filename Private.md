# 공통 
<details>
  <summary><h3>1. 가장 기억에 남는 프로젝트와 그 이유는 무엇인가요?</h3></summary>
가장 기억에 남는 프로젝트는 대학교 졸업 프로젝트인 "Unip"입니다.
<br>
이 프로젝트는 팀원들의 프로그래밍 지식이 부족한 상황에서 제가 전반적인 기획, 일정 관리, 그리고 소통을 주도하며 성공적으로 진행한 경험 때문에 특히 기억에 남습니다.
<br>
팀원들의 기술적으로 미숙한 점을 보완하기 위해 전체 프로젝트의 일정을 설정하고 노션, 디스코드를 이용해 주기적으로 진행 상황 숙지를 통해서 체계적으로 관리했습니다. 또한 프론트엔드 개발 경험이 부족한 팀원을 위해, 우선 백엔드 서버를 신속하게 개발 후 프론트엔드 구현 과정에서 발생하는 문제를 백엔드 측면에서 지원하여 원활한 통합을 도왔습니다.
<br>
이 프로젝트를 통해 프로젝트 관리와 리더십, 그리고 문제 해결 능력 향상을 경험할 수 있었습니다.
</details>

# UniP
<details>
  <summary><h3>1. 프로젝트 진행 중 겪은 주요 문제점과 이를 어떻게 해결했는지 설명해 주세요.</h3></summary>
이 프로젝트는 팀원들의 프로그래밍 지식이 부족한 상황에서 제가 전반적인 기획, 일정 관리, 그리고 소통을 주도하며 성공적으로 진행한 경험 때문에 특히 기억에 남습니다.
<br>
팀원들의 기술적으로 미숙한 점을 보완하기 위해 전체 프로젝트의 일정을 설정하고 노션, 디스코드를 이용해 주기적으로 진행 상황 숙지를 통해서 체계적으로 관리했습니다. 또한 프론트엔드 개발 경험이 부족한 팀원을 위해, 우선 백엔드 서버를 신속하게 개발 후 프론트엔드 구현 과정에서 발생하는 문제를 백엔드 측면에서 지원하여 원활한 통합을 도왔습니다.
<br>
이 프로젝트를 통해 프로젝트 관리와 리더십, 그리고 문제 해결 능력 향상을 경험할 수 있었습니다.
</details>

<details>
  <summary><h3>2. 프로젝트에서 본인의 역할과 팀 내 협업 경험에 대해 이야기해 주세요.</h3></summary>
이 프로젝트에서 저는 팀장을 맡아 전체 기획, UX/UI 설계, 그리고 백엔드 개발을 주도했습니다. 초기 단계에서는 프로그래밍 지식이 부족한 팀원들을 지원하기 위해 기획과 디자인을 신속하게 마무리하고, 메인 서버 개발을 빠르게 진행하여 팀원들이 안정적인 기반 위에서 작업할 수 있도록 했습니다.

또한, 메인 서버 개발을 통해 통일된 API 규약을 정립하여 팀원들이 기능을 연동하는 과정에서 혼란이 없도록 했습니다. 정기적인 회의와 지속적인 피드백을 통해 팀원들이 기술을 익히도록 돕고, 구현 과정에서 필요한 수정 사항을 신속히 반영함으로써 개발 효율성을 높였습니다.

그 결과, 프로젝트는 마감 하루 전에 성공적으로 완료되었습니다. 체계적인 일정 관리와 주도적인 역할 수행 덕분에 프로젝트를 기한 내에 마칠 수 있었다고 생각합니다.
</details>

<details>
  <summary><h3>3. 프로젝트의 아키텍처 설계 및 기술 스택 선택 기준은 무엇이었나요?</h3></summary>
  
### JWT를 선택한 이유
이 프로젝트에서는 초기 기획 단계부터 채팅 기능을 포함해야 했습니다. 채팅 구현 시 실시간 사용자 인증과 세션 관리가 중요한데, 전통적인 세션 기반 인증 방식은 상태 정보를 서버에 저장해야 하므로 만약 채팅 서버를 분리한다면 확장성과 유지 관리 측면에서 어려움이 있을 것으로 예상되어 JWT를 선택하게 되었습니다. 
  ### Redis로 보안을 강화한 이유?
현재 프로젝트는 만남 서비스의 특성상 사용자 인증이 매우 중요합니다. 이메일 인증과 JWT를 Redis에 저장함으로써, 토큰 탈취 등의 보안 위협에 대해 어느 정도 면역력을 갖출 수 있다고 판단했습니다. 또한, Redis를 활용하면 TTL(Time To Live) 설정을 통해 만료된 토큰을 자동으로 관리할 수 있어, 보안과 시스템 신뢰성을 유지하면서도 비용 대비 효과적인 운영이 가능하다고 생각했습니다.
  ### 왜 MariaDB를 사용했나요?
저는 학생 신분으로 비용 부담을 줄이기 위해 국내 무료 배포 사이트를 활용했습니다. 해당 사이트는 MySQL 대신 MariaDB를 지원하고 있었는데, AWS 프리티어 정책 변경으로 인해 Public IP로 RDB를 운영할 경우 추가 비용이 발생할 수 있었기 때문입니다. 이러한 비용 문제와 학습 환경의 제약을 고려하여, 무료로 제공되는 MariaDB를 선택하게 되었습니다.
  #### 꼬리 질문 (프로젝트가 확장될 때 이 선택이 어떤 한계를 가질 수 있을까요?)
현재 무료 배포 사이트는 초기 학습 및 소규모 서비스 운영에는 적합하지만, 프로젝트가 확장되어 사용자가 대폭 늘어나게 되면 성능 및 확장성에 제약이 생기며 안정성이 떨어질 것 같습니다. 그렇기에 향후 사용자가 많아지면 AWS와 같은 대형 클라우드 서비스로 인프라를 확장하는 것이 바람직하다고 판단됩니다. 다행히도 저는 AWS 배포에 대해 어느정도 숙지했기에 원활하게 전환이 가능할 것으로 생각됩니다.
</details>

<details> 
  <summary><h3>4. 포트폴리오에 복합 인덱스 설계 및 구현에 대해 더 자세히</h3></summary> 처음에는 페이징 구현 시 인덱스를 활용해야 한다는 점만 고려하여 인덱스를 단순하게 설계했습니다. 하지만 이후 데이터베이스 학습을 통해 복합 인덱스의 개념과 인덱스 순서의 중요성을 이해하게 되었고, 이를 개선하여 구현하였습니다.
제 프로젝트에서는 사용자가 파티를 생성하고 참여할 수 있으며, 게시판처럼 검색 기능이 필요했습니다. 검색 시 파티 타입과 종료 여부를 기준으로 필터링하는데, 이 과정에서 복합 인덱스를 구성하였으며, MySQL의 InnoDB 기준으로 적절한 순서를 고려하여 설계하였습니다.
특히, 파티는 데이터베이스에서 물리적으로 삭제되지 않고 논리적 삭제 방식이 적용되므로, 종료 여부를 우선적으로 검색하는 것이 비즈니스 로직상으로도, DB 동시성 측면에서도 더 효율적이라고 판단했습니다. 이를 통해 InnoDB의 갭 락(Gap Lock) 범위를 최대 90% 감소시켜 트랜잭션 대기 시간을 단축하고 동시성을 크게 향상시킬 수 있었습니다.
</details>

<details> 
  <summary><h3>5. 포트폴리오에 무한 페이징 최적화에 대해 자세히</h3></summary> 
  
프로젝트에서 개설된 파티 목록을 확인할 수 있는 기능을 구현해야 했습니다. 저희 프로젝트는 Flutter 기반 앱이므로, 무한 스크롤을 지원하는 것이 사용자 경험(UX) 측면에서 더 적합하다고 판단했습니다.
초기에는 OFFSET 방식을 사용하여 무한 스크롤을 구현했지만, 두 가지 문제가 발생했습니다.
- 데이터가 많아질수록 성능 저하가 발생했습니다.
- 페이지의 끝부분에서 일부 파티가 중복 표시되는 문제가 있었습니다.
이는 OFFSET 방식의 고질적인 단점으로, 이를 해결하기 위해 Keyset Paging(키셋 페이징) 방식을 적용하였습니다.

그 결과, 페이지 이동 속도가 100만 건 기준 4초에서 100ms 이하로 단축되었으며, 대규모 데이터에서도 일관된 성능을 유지할 수 있었습니다.
</details>

<details> 
  <summary><h3>6. 포트폴리오에서 인증 이메일 비동기화 처리에 대해 </h3></summary> 
이메일 인증 과정에서 SMTP 전송으로 인해 요청 시간이 약 4초가 소요되었습니다. 이로 인해 **사용자가 이메일 발송 버튼을 누를 때 4초 동안 대기해야 했으며, 데이터베이스 커넥션 측면에서도 비효율적**이라고 판단했습니다.
사용자 경험(UX)을 고려했을 때, 이메일 인증 메일은 실시간으로 처리될 필요가 없다고 생각하여 비동기 방식으로 전환하였습니다. 이를 위해 비동기 전용 스레드 풀을 정의하여 여러 요청을 동시에 처리할 수 있도록 개선했습니다.

그 결과, SMTP 요청 시간을 제외한 응답 속도가 4초에서 약 100ms로 단축되었으며, DB 커넥션 유지 시간이 감소하여 전반적인 성능이 향상되었습니다.

#### 꼬리 질문 비동기 전용 스레드 풀을 정의했다는데, 어떻게 구현했나요?
"Spring의 @Async와 ThreadPoolTaskExecutor를 사용하여 비동기 처리를 구현했습니다.
SMTP는 I/O 바운드 작업이므로 대기 시간이 많아 동시 요청 처리가 중요합니다.
이에 따라 코어 풀 크기를 (CPU 코어 수 * 2)로 설정하여 기본적인 동시성을 확보했으며,
현재 트래픽이 많지 않아 최대 풀 크기는 코어 풀과 동일하게 설정했습니다.
향후 트래픽 증가 시 실제 동시 요청량과 처리 지연 시간을 모니터링하여 maxPoolSize와 queueCapacity를 단계적으로 조정할 계획입니다."

</details>

# +/KM

<details>
  <summary><h3>1. 프로젝트 진행 중 겪은 주요 문제점과 이를 어떻게 해결했는지 설명해 주세요.</h3></summary>
  
당 프로젝트에서 가장 중요한 요소는 **공간 데이터의 효율적인 조회**였습니다. 이를 최적화하는 방법에 대해 깊이 고민했으며, 초기에는 MySQL을 기반으로 쿼리를 튜닝하여 성능을 개선하려 했습니다. 그러나 **MySQL의 공간 데이터 처리 한계를 경험하면서**, 더 적합한 데이터베이스 도입을 고민하게 되었습니다.
</details>

<details>
  <summary><h3>2. 왜 MySQL에서 공간데이터 처리가 한계가 있나요?.</h3></summary>
InnoDB에서 R-Tree인덱스를 지원하지 않습니다. 대신 B-Tree 기반의 인덱스를 사용해야 하는데 이것은 비효율적이였습니다. 또한 공간 연산 기능이 제한적이였습니다. MySQL의 공간 함수들은 대체로 인덱스 활용이 매우 떨어졌습니다. 성능을 개선하기 위해 쿼리에서 폴리곤 영역을 직접 지정하여 연산 범위를 줄이는 최적화 작업을 진행했지만 여전히 대량 데이터 처리에서는 한계가 존재했습니다. 이러한 문제를 해결하기 위해 MongoDB의 공간 데이터 기능(GeoJSON, 2dsphere 인덱스)을 활용했습니다.
MongoDB는 공간 검색에 최적화된 인덱스를 제공하며, 대규모 데이터에서도 더 나은 성능을 보였습니다.
</details>

<details>
  <summary><h3>3. 포트폴리오에서 공공데이터 CSV 파일 갱신 문제에 대해</h3></summary>
CSV 파일 갱신 초기에는 JPA의 saveAll()과 deleteAll()을 사용했지만, 10만 건의 데이터를 처리하는 데 최대 3분이 소요되는 성능 문제가 발생했습니다. 이는 두 메서드가 개별적으로 save()와 delete() 쿼리를 실행하면서 영속성 컨텍스트를 유지해 불필요한 연산이 발생했기 때문입니다. 이를 해결하기 위해 JPA의 영속성 컨텍스트를 사용하지 않는 JDBC Batch를 적용했고, 데이터 처리 속도를 대폭 개선할 수 있었습니다. Spring Batch도 고려했지만, 10만 건의 데이터 처리에는 오버 엔지니어링이 될 가능성이 높아 상대적으로 가벼운 JDBC Batch가 더 적합하다고 판단했습니다.  
</details>

<details>
  <summary><h3>4. 포트폴리오에서 MySQL 공간 인덱스 최적화에 대해 </h3></summary>
공공데이터 포털의 의료 데이터를 활용해 병원과 약국 정보를 저장하고 반경 기반 조회 기능을 개발하는 과정에서, 임의의 좌표를 기준으로 검색할 때 MySQL의 ST_Buffer 함수를 사용하니 실행 시간이 1681ms에 달하는 문제가 발생했습니다. 이는 ST_Buffer가 실행 시마다 버퍼 영역을 계산하여 결과값이 사전에 인덱싱되어 있지 않아 인덱스 필터링 효과가 떨어지기 때문입니다. 이를 해결하기 위해 서버단에서 POLYGON을 미리 정의하여 MBR 기반 인덱스를 보다 효과적으로 활용하도록 최적화하였고, 그 결과 쿼리 실행 시간이 약 55% 단축되어 전체 시스템 응답 속도가 크게 개선되었습니다.
</details>

<details>
  <summary><h3>5. 포트폴리오에서 MongoDB에 대해 </h3></summary>
MySQL의 InnoDB는 R-Tree 인덱스를 지원하지 않아 B-Tree 기반 인덱스를 사용해야 하는데, 이 방식은 공간 데이터 조회에 비효율적입니다. 또한, MySQL의 공간 함수들은 인덱스 활용도가 낮아 쿼리에서 폴리곤 영역을 직접 지정해 연산 범위를 줄이는 최적화 작업을 진행했지만, 대량 데이터 처리에는 한계가 있었습니다. 이러한 문제를 해결하기 위해 MongoDB의 GeoJSON과 2dsphere 인덱스를 활용하여 공간 관련 쿼리 성능을 개선했고, 그 결과 평균 84.34%의 조회 속도 향상을 달성했습니다. 또한, MySQL은 데이터의 연관성을 유지하고, MongoDB는 공간 조회 기능을 전담함으로써 각 데이터베이스가 적합한 역할을 수행하도록 책임을 분산시켰습니다. 게다가 MongoDB는 오픈 소스 기반이므로 라이선스 비용이 낮고, 기존 MySQL의 공간 조회 기능을 MongoDB로 전담시킴으로써 비용 대비 효과가 매우 크다고 판단했습니다.
</details>

